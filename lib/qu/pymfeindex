#!/usr/bin/env python
from __future__ import division

import os
import sys
import datetime
from time import time
from optparse import OptionParser
import sqlite3

import platform
import subprocess
import re
from struct import *
from heapq import *
from tempfile import TemporaryFile

D2n_dic = dict(A=0, T=3, C=2, G=1, a=0, t=3, c=2, g=1)
n2D_dic = {0:'A', 3:'T', 2:'C', 1:'G', 0:'a', 3:'t', 2:'c', 1:'g'}

class Chunk:
    def __init__(self, item_len, f, pos):
        self.file = f
        self.file_pos = pos
        self.item_len = item_len
        self.count = 0

    def __iter__(self):
        '''generator function to iterate through the stored data'''
        if self.count == 0:
            return

        item_len = self.item_len
        max_seg_len = 1000
        for seg_start in range(0, self.count, max_seg_len):
            self.file.seek(self.file_pos + seg_start * item_len, 0)
            if seg_start + max_seg_len <= self.count:
                seg_len = max_seg_len
            else:
                seg_len = self.count - seg_start
            seg = self.file.read(seg_len * item_len)
            
            for i in range(seg_len):
                yield seg[i * item_len:(i + 1) * item_len]
        

class MergeSorter:
    '''class to handle spilling excess data to temporary files and
    merging it when reading it back'''

    '''limit individual file size to 2G'''
    max_file_size = 2000000000
    tmp_files = []
    chunks = []

    def __init__(self, l):
        self.len = l

    def new_tmp_file(self):
        f = TemporaryFile()
        self.tmp_files.append(f)
        return f

    def get_curr_file_num(self):
        if len(self.tmp_files) > 0:
            return self.tmp_files[-1]
        else:
            return self.new_tmp_file()

    def store(self, data):
        f = self.get_curr_file_num()
        pos = f.tell()

        chunk = Chunk(self.len, f, pos)

        data.sort()

        for item in data:
            f.write(item)
            chunk.count += 1
            pos += self.len
            if pos >= self.max_file_size:
                self.chunks.append(chunk)
                f = self.new_tmp_file()
                pos = 0
                chunk = Chunk(self.len, f, pos)

        if pos > 0:
            self.chunks.append(chunk)

    def store_last(self, data):
        data.sort()
        self.chunks.append(data)

    def __iter__(self):
        '''Use the heapq merge function to get an iterator that merges
        all the chunks together'''
        return merge(*self.chunks)
    
def print_usage():
    print '''
%s: Index DB for MFEprimer-2.0

Usage:

    %s -f human.genomic -k 9 -o index_db_name

Author: Wubin Qu <quwubin@gmail.com>
Last updated: 2012-9-28
    ''' % (os.path.basename(sys.argv[0]), os.path.basename(sys.argv[0]))

def optget():
    '''parse options'''
    parser = OptionParser()
    parser.add_option("-f", "--file", dest = "filename", help = "DNA file in fasta to be indexed")
    parser.add_option("-k", "--k", dest = "k", type='int', help = "K mer , default is 9", default = 9)
    parser.add_option("-o", "--out", dest = "out", help = "Index db file name")
    parser.add_option("-c", "--chunk", dest = "chunk", help = "Number of kmers to sort in memory", default=1000000)

    (options, args) = parser.parse_args()

    if not options.filename:
        print_usage()
        exit()

    if not options.out:
        options.out = options.filename + '.sqlite3.db'

    if options.chunk < 10000:
        options.chunk = 10000

    return options

def parse_fasta_format(fh):
    '''
    A Fasta-format Parser return Iterator
    '''
    # Remove the comment and blank lines before the first record
    while True:
        line = fh.readline()
        if not line: return # Blank line

        line = line.strip()

        if line.startswith('>'):
            break

    while True:
        if not line.startswith('>'):
            raise ValueError("Records in Fasta files should start with '>' character")

        id, sep, desc = line[1:].partition(' ')

        seq_lines = []
        line = fh.readline()
        while True:
            if not line: break

            line = line.strip()

            if line.startswith('>'):
                break

            if not line:
                line = fh.readline()
                continue

            seq_lines.append(line.replace(' ', '').replace("\r", ''))
            line = fh.readline()

        yield (id, desc, ''.join(seq_lines))

        if not line: return

    assert False, 'Should not reach this line'

def insert_db(conn, mer_count, plus, minus):
    for mer_id in xrange(mer_count):
        conn.execute("insert into pos (mer_id, plus, minus) values (?, ?, ?)", \
                [mer_id, plus[mer_id], minus[mer_id]])

    conn.commit()

def update_db(conn, mer_count, plus, minus):
    for mer_id in xrange(mer_count):
        (plus_data, minus_data) = conn.execute("select plus, minus from pos where mer_id=?", [mer_id]).fetchone()
        if plus_data:
            if plus[mer_id]:
                plus_data += ';%s' % plus[mer_id]
            else:
                pass
        else:
            plus_data = plus[mer_id]

        if minus_data:
            if minus[mer_id]:
                minus_data += ';%s' % minus[mer_id]
            else:
                pass
        else:
            minus_data = minus[mer_id]

        conn.execute("update pos set plus=?, minus=? where mer_id=?", \
                [plus_data, minus_data, mer_id])

    conn.commit()

def baseN(num, b):
    '''convert non-negative decimal integer n to
    equivalent in another base b (2-36)'''
    return ((num == 0) and  '0' ) or ( baseN(num // b, b).lstrip('0') + "0123456789abcdefghijklmnopqrstuvwxyz"[num % b])

def int2DNA(num, k):
    seq = baseN(num, 4)
    return 'A' * (k-len(seq)) + (''.join([n2D_dic[int(base)] for base in seq]))

def DNA2int_2(seq):
    '''convert a sub-sequence/seq to a non-negative integer'''
    plus_mer = 0
    minus_mer = 0
    length = len(seq) - 1
    for i, letter in enumerate(seq):
        plus_mer += D2n_dic[letter] * 4 ** (length - i)
        minus_mer += (3 - D2n_dic[letter]) * 4 ** i

    return plus_mer, minus_mer

def DNA2int(seq):
    '''convert a sub-sequence/seq to a non-negative integer'''
    plus_mer = 0
    length = len(seq) - 1
    for i, letter in enumerate(seq):
        plus_mer += D2n_dic[letter] * 4 ** (length - i)

    return plus_mer

def store_to_db(conn, mer_id, next_mer_id, collation, record_names):
    if mer_id >= 0:
        plus = ";".join('%s:%s' % (record_names[x[0]], ",".join(str(y) for y in x[1])) for x in collation['+'])
        minus = ";".join('%s:%s' % (record_names[x[0]], ",".join(str(y) for y in x[1])) for x in collation['-'])
        conn.execute("insert into pos (mer_id, plus, minus)"
                     "values (?, ?, ?)", (mer_id, plus, minus))

    conn.executemany("insert into pos (mer_id, plus, minus)"
                     "values (?, ?, ?)",
                     ((x, '', '') for x in range(mer_id + 1, next_mer_id)))

def index(filename, k, dbname, max_count):
    ''''''
    start = time()

    mer_count = 4**k

    conn = sqlite3.connect(dbname)
    cur = conn.cursor()
    cur.executescript('''
    drop table if exists pos;
    create table pos(
    mer_id integer primary key,
    plus text,
    minus text
    );''')


    count = 0
    record_num = 0
    record_names = []

    # Format for packing data.  By using big-endian byte ordering,
    # we get the result that a simple sort will put everything in the order
    # we want.
    if k > 16:
        fmt = '>QII'
    else:
        fmt = '>III'

    fmt_len = calcsize(fmt)
    sorter = MergeSorter(fmt_len)

    # Accumulator for packed data items
    items = []

    # Get data and sort
    for record_id, record_desc, fasta_seq in parse_fasta_format(open(filename)):
        is_empty = False
        print record_id
        record_names.append(record_id)
        record_num = len(record_names) - 1

        for i in xrange(len(fasta_seq)-k + 1):
            kmer = fasta_seq[i:(i+k)]

            try:
                plus_mer_id, minus_mer_id = DNA2int_2(kmer)
            except:
                # Skip the unrecognized base, such as 'N'
                continue

            items.append(pack(fmt, plus_mer_id, record_num, i + k - 1))
            items.append(pack(fmt, minus_mer_id, record_num | 0x80000000, i))
            count += 2

            if count >= max_count:
                sorter.store(items)
                items = []
                count = 0
                
    # Don't forget the last bit
    sorter.store_last(items)

    # Merge it all together
    last_kmer = -1
    last_collation = { '+' : [], '-' : [] }
    
    for item in sorter:
        mer_id, record_num, pos = unpack(fmt, item)
        if record_num < 0x80000000:
            dirn = '+'
        else:
            record_num &= 0x7fffffff
            dirn = '-'
        
        if mer_id != last_kmer:
            store_to_db(conn, last_kmer, mer_id, last_collation, record_names)
            last_kmer = mer_id
            last_collation = { '+' : [], '-' : [] }

        if (len(last_collation[dirn]) == 0
            or last_collation[dirn][-1][0] != record_num):
            last_collation[dirn].append((record_num, []))
        last_collation[dirn][-1][1].append(pos)

    store_to_db(conn, last_kmer, mer_count, last_collation, record_names)
    conn.commit()

    print "Time used: %s" % str(datetime.timedelta(seconds=(time() - start)))
    print 'Done.'

def main():
    '''main'''
    options = optget()
    index(options.filename, options.k, options.out, options.chunk)

if __name__ == "__main__":
    main()

